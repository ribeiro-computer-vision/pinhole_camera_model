{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLeXp_S6bjbt"
   },
   "source": [
    "# The pinhole camera model: perspective transformation\n",
    "\n",
    "In these notes, we follow the mathematical notation from Prince's book (Computer Vision Models).\n",
    "\n",
    "The geometry of the perspective camera is shown in Figure 1.   \n",
    "\n",
    "<img src=\"pinhole_camera.jpg\" alt=\"geometry01\" style=\"zoom:100%;\" />\n",
    "\n",
    "**Figure 1**: The geometry of the perspective projection transformation (the pinhole camera). The camera center is located at point $C$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit function form\n",
    "\n",
    "The pinhole camera model maps 3-D points on an object to 2-D points on the image plane (Figure 1). A point ${\\bf w} = (u,v,w)^\\mathsf{T}$ on the object to an image point ${\\bf x} = (x,y)^\\mathsf{T}$ on the image plane of the pinhole camera according to the following model (explicit function form):\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    x &= \\frac{\\phi_x\\left(\\omega_{11}u + \\omega_{12}v + \\omega_{13}w + \\tau_x \\right) + \\gamma\\left(\\omega_{21}u + \\omega_{22}v + \\omega_{23}w + \\tau_y\\right)}\n",
    "        {\\omega_{31}u + \\omega_{32}v + \\omega_{33}w + \\tau_z} + \\delta_x,\\notag\\\\\n",
    "    y &= \\frac{\\phi_y\\left(\\omega_{21}u + \\omega_{22}v + \\omega_{23}w + \\tau_y \\right)}\n",
    "        {\\omega_{31}u + \\omega_{32}v + \\omega_{33}w + \\tau_z} + \\delta_y.\n",
    "       % \\label{pinhole_explicit}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which can be written as a function:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "{\\bf x} = \\text{pinhole}\\left[{\\bf w}, \\Lambda,\\Omega,\\boldsymbol{\\tau}\\right],\n",
    "\\tag{2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\Lambda$ is the set of intrinsic parameters, $\\Omega$ is the camera rotation, and $\\boldsymbol{\\tau}$ is the 3-D location of the camera center (i.e., translation). For each world point ${\\bf w}\\in \\mathbb{R}^3$, the pinhole-camera model generates an image point ${\\bf x}\\in \\mathbb{R}^2$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pinhole camera in matrix form\n",
    "The pinhole-camera model is a non-linear function. This nonlinearity means that the function cannot be expressed as a single matrix in Cartesian coordinates, which are coordinates of points in Euclidean space. However, we can convert the points (and also transformations) from Euclidean space to Projective space (https://en.wikipedia.org/wiki/Homogeneous_coordinates). In projective space, the location of points is given by homogeneous coordinates (or projective coordinates). This conversion has the advantage that all transformations in projective space are linear and, as a result, can be expressed by transformation matrices.  \n",
    "\n",
    "The explicit form of the pinhole-camera model in Equation 1 can be written in matrix form (in  homogeneous coordinates) is given by:\n",
    "\n",
    "$$\n",
    "\\begin{align}    \n",
    "    \\lambda\n",
    "    \\begin{bmatrix}\n",
    "        x \\\\\n",
    "        y \\\\\n",
    "        1\n",
    "    \\end{bmatrix}\n",
    "    =  \n",
    "    \\underbrace{\\begin{bmatrix}\n",
    "        {\\phi_x} & {\\gamma} & {\\delta_x} & 0 \\\\\n",
    "         0     & {\\phi_y} & {\\delta_y} & 0 \\\\\n",
    "         0     & 0      & 1        & 0 \n",
    "    \\end{bmatrix}}_{\\text{intrinsic matrix}}\n",
    "    \\underbrace{\\begin{bmatrix}\n",
    "        {\\omega_{11}} & {\\omega_{12}} & {\\omega_{13}} & {\\tau_x} \\\\\n",
    "        {\\omega_{21}} & {\\omega_{22}} & {\\omega_{23}} & {\\tau_y} \\\\\n",
    "        {\\omega_{31}} & {\\omega_{32}} & {\\omega_{33}} & {\\tau_z} \\\\\n",
    "         0          & 0           & 0           & 1 \n",
    "    \\end{bmatrix}}_{\\text{extrinsic matrix}}\n",
    "    \\begin{bmatrix}\n",
    "        u \\\\\n",
    "        v \\\\\n",
    "        w \\\\\n",
    "        1\n",
    "    \\end{bmatrix}, \n",
    "    \\tag{3}\n",
    "\\end{align}\n",
    "$$\n",
    "or in short (block matrix notation):\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\lambda \\tilde{{\\bf x}} = \n",
    "    \\Lambda\n",
    "    \\begin{bmatrix}\n",
    "        \\Omega & {\\boldsymbol{\\tau}}\n",
    "    \\end{bmatrix} \\tilde{{\\bf w}}. \n",
    "        \\tag{4}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical example (single point with synthetic camera)\n",
    "\n",
    "In this example, our goal to project a vertex of a 3-D virtual object onto the image of the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import imageio\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 3-D point\n",
    "The 3-D vertex is located at ${\\bf w} = \\left(10,-10,20\\right)^\\mathsf{T}$, and its color is blue, i.e., **rgb**(0,0,255)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w =\n",
      "[[ 10]\n",
      " [-10]\n",
      " [ 20]]\n"
     ]
    }
   ],
   "source": [
    "# Coordinates of the 3-D vertex\n",
    "w = np.array([[10], [-10], [20]])   # Column vector\n",
    "print(\"w =\")\n",
    "print(w)\n",
    "\n",
    "# Vertex color\n",
    "c = np.array([0,0,255])   # RGB color components (blue color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera model (intrinsic and extrinsic parameters)\n",
    "Assume that an image of a real scene is captured by a static camera that has the following parameters:\n",
    "\n",
    "- **Focal lengths**: $\\phi_x = 200$ and $\\phi_y = 205$,\n",
    "- **Principal point**: $\\delta_x = 401$ and $\\delta_y=305$,\n",
    "- **Skew**: 0\n",
    "- **Rotation**: 0 degrees,\n",
    "- **Translation**: $\\boldsymbol{\\tau}=\\left(10,0,0\\right)^\\mathsf{T}$,\n",
    "- **Image size (width,height)**:  $800\\times600$ pixels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda = \n",
      "[[200.   0. 401.]\n",
      " [  0. 205. 305.]\n",
      " [  0.   0.   1.]]\n",
      "\n",
      "\n",
      "Omega = \n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "\n",
      "tau = \n",
      "[[10]\n",
      " [ 0]\n",
      " [ 0]]\n"
     ]
    }
   ],
   "source": [
    "# Intrinsic parameters\n",
    "phi_x   = 200.0\n",
    "phi_y   = 205.0\n",
    "skew    =   0.0\n",
    "delta_x = 401\n",
    "delta_y = 305 \n",
    "\n",
    "\n",
    "# Matrices (perspective projection model)\n",
    "Lambda = np.array([[phi_x,  skew, delta_x],\n",
    "                   [    0, phi_y, delta_y],\n",
    "                   [    0,     0,       1]])\n",
    "\n",
    "print(\"Lambda = \")\n",
    "print(Lambda)\n",
    "\n",
    "# Extrinsic parameters\n",
    "Omega = np.eye(3,3)\n",
    "tau   = np.array([[10], [0], [0]])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Omega = \")\n",
    "print(Omega)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"tau = \")\n",
    "print(tau)\n",
    "\n",
    "# Image size (resolution)\n",
    "im_width  = 800\n",
    "im_height = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here, we need to perform two basic steps: \n",
    " 1. Calculate the image coordinates $(x,y)$ of the vertex using the pinhole camera model, and \n",
    " 2. Set the color of the pixel at $(x,y)$ to the desired color, i.e., **rgb**(0,0,255)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Find the image coordinates of the vertex as seen by the camera:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\lambda\n",
    "    \\begin{bmatrix}\n",
    "        x \\\\\n",
    "        y \\\\\n",
    "        1\n",
    "    \\end{bmatrix}\n",
    "    &=  \n",
    "    \\underbrace{\\begin{bmatrix}\n",
    "        200    &   0 & 401 \\\\\n",
    "         0     & 205 & 305 \\\\\n",
    "         0     & 0   & 1    \n",
    "    \\end{bmatrix}}_{\\text{intrisic matrix}}\n",
    "    \\underbrace{\\begin{bmatrix}\n",
    "        1 & 0 & 0 & 10 \\\\\n",
    "        0 & 1 & 0 & 0 \\\\\n",
    "        0 & 0 & 1 & 0 \\\\\n",
    "    \\end{bmatrix}}_{\\text{extrinsic matrix}}\n",
    "    \\begin{bmatrix}\n",
    "        10 \\\\\n",
    "        -10 \\\\\n",
    "        20 \\\\\n",
    "        1\n",
    "    \\end{bmatrix} \\notag\\\\\n",
    "    &=\n",
    "        \\begin{bmatrix}\n",
    "        12020 \\\\\n",
    "        4050 \\\\\n",
    "        20\n",
    "    \\end{bmatrix} \\implies\n",
    "    \\begin{cases}\n",
    "    \tx &= \\frac{\\lambda x}{\\lambda} = \\frac{12020}{20} = 601 \\\\\n",
    "\t\t\ty &= \\frac{\\lambda y}{\\lambda} = \\frac{4050}{20} = 202.5\n",
    "    \\end{cases}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_tilde = \n",
      "[[ 10]\n",
      " [-10]\n",
      " [ 20]\n",
      " [  1]]\n",
      "\n",
      "x_tilde = \n",
      "[[12020.]\n",
      " [ 4050.]\n",
      " [   20.]]\n",
      "\n",
      "x = \n",
      "[601.] [202.5]\n"
     ]
    }
   ],
   "source": [
    "# Convert vertex coords to homogeneous coordinates\n",
    "w_tilde = np.block([[w],[1]])\n",
    "print(\"w_tilde = \")\n",
    "print(w_tilde)\n",
    "\n",
    "# Calculate perspective projection of vertex onto image\n",
    "x_tilde = Lambda @ np.block([Omega, tau]) @ w_tilde\n",
    "\n",
    "print(\"\\nx_tilde = \")\n",
    "print(x_tilde)\n",
    "\n",
    "# Convert coordinates from homogeneous to Cartesian\n",
    "x = x_tilde[0] / x_tilde[2]\n",
    "y = x_tilde[1] / x_tilde[2]\n",
    "\n",
    "print(\"\\nx = \")\n",
    "print(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set the color of the image pixel to the desired color:\n",
    "\n",
    "   $$\n",
    "   I(202, 601) \\leftarrow rgb(0,0,255).\n",
    "   $$\n",
    "\n",
    "Here, $I$ is the image matrix. Its dimension is $600\\times 800$ (i.e., rows $\\times$ columns), and the matrix is indexed using $(i,j)$ indices. Note $(i,j)$ indices and $(x,y)$ coordinates are not equal. Instead, x-values vary with the columns of the matrix (i.e., index $j$) while y-values vary with the rows of the matrix (i.e., index $i$).  \n",
    "\n",
    "When projecting several vertices of a 3-D object, the above two steps are repeated for all points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projecting multiple points\n",
    "\n",
    "When projecting multiple points, we can stack all points as columns of a matrix and then apply the multiplication transformation directly on the matrix. For instance, the following matrix stores the 3-D coordinates of the vertices of a cube.  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "C =\n",
    "\\begin{bmatrix}\n",
    "   {\\bf w}_1 & \\dots & {\\bf w}_N\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "   0 & 50 & 50 & 0 & 0 & 50 & 50 & 0\\\\ 0 & 0 & 50 & 50 & 0 & 0 & 50 & 50\\\\ 200 & 200 & 200 & 200 & 250 & 250 & 250 & 250\n",
    "  % \\label{eq_Cube1}\n",
    "\\end{bmatrix}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Each column of matrix $C$ is a vertex ${\\bf w}_i = \\left(u_i,v_i,w_i\\right)^\\mathsf{T}$ of a cube, for $i=1,\\dots,8$.  The cube is located in front of the camera as the example shown in Figure 1. The projection operation is then given by:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\lambda \\tilde{{\\bf x}} =\n",
    "    \\Lambda\n",
    "    \\begin{bmatrix}\n",
    "        \\Omega & {\\boldsymbol{\\tau}}\n",
    "    \\end{bmatrix} \\tilde{C},  \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\tilde{C}$ is the cube points given in homogeneous coordinates, i.e.:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\tilde{C} =\n",
    "\\begin{bmatrix}\n",
    "   \\tilde{\\bf w}_1 & \\dots & \\tilde{\\bf w}_N\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "   0 & 50 & 50 & 0 & 0 & 50 & 50 & 0\\\\\n",
    "   0 & 0 & 50 & 50 & 0 & 0 & 50 & 50\\\\\n",
    "   200 & 200 & 200 & 200 & 250 & 250 & 250 & 250 \\\\\n",
    "   1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\n",
    "\\end{bmatrix}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_project_points(W, Lambda, Rt):\n",
    "    \n",
    "    # Convert points to homogeneous coords\n",
    "    W_tilde = np.block([[W],[np.ones([1,np.shape(W)[1]])]])\n",
    "    \n",
    "    print(\"w_tilde = \", W_tilde)\n",
    "\n",
    "    # Calculate perspective projection\n",
    "    X_tilde = Lambda @ Rt @ W_tilde\n",
    "    \n",
    "    print(\"w_tilde = \", X_tilde)\n",
    "\n",
    "    \n",
    "    # Convert coordinates from homogeneous to Cartesian\n",
    "    X = np.zeros([2,np.shape(W)[1]])          # Create matrix to store image coords\n",
    "\n",
    "    X[0][:] = X_tilde[0][:] / X_tilde[2][:]   # Vectorized division \n",
    "    X[1][:] = X_tilde[1][:] / X_tilde[2][:]\n",
    "            \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_tilde =  [[ 0. 30.  0.  0.]\n",
      " [ 0.  0. 30.  0.]\n",
      " [ 0.  0.  0. 30.]\n",
      " [ 1.  1.  1.  1.]]\n",
      "w_tilde =  [[-2000.  4000. -2000. 10030.]\n",
      " [    0.     0.  6150.  9150.]\n",
      " [    0.     0.     0.    30.]]\n",
      "\n",
      "x = \n",
      "[[        -inf          inf         -inf 334.33333333]\n",
      " [         nan          nan          inf 305.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fd/1_wj4s6n5dz9mph8lxngjxyh0000gn/T/ipykernel_15523/4115657872.py:17: RuntimeWarning: divide by zero encountered in divide\n",
      "  X[0][:] = X_tilde[0][:] / X_tilde[2][:]   # Vectorized division\n",
      "/var/folders/fd/1_wj4s6n5dz9mph8lxngjxyh0000gn/T/ipykernel_15523/4115657872.py:18: RuntimeWarning: divide by zero encountered in divide\n",
      "  X[1][:] = X_tilde[1][:] / X_tilde[2][:]\n",
      "/var/folders/fd/1_wj4s6n5dz9mph8lxngjxyh0000gn/T/ipykernel_15523/4115657872.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  X[1][:] = X_tilde[1][:] / X_tilde[2][:]\n"
     ]
    }
   ],
   "source": [
    "# Coordinate system \n",
    "W   = 30 * np.array([\n",
    "    [ 0, 1,  0,  0],\n",
    "    [ 0, 0,  1,  0],\n",
    "    [ 0, 0,  0,  1]\n",
    "    ])\n",
    "\n",
    "# Using inverse because we are going from world to camera, i.e., \n",
    "# The origin of the world is not the camera origin. \n",
    "Rt = np.block([Omega.T, -Omega.T @ tau])\n",
    "\n",
    "image_points = my_project_points(W, Lambda, Rt)\n",
    "\n",
    "print(\"\\nx = \")\n",
    "print(image_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_coordinate_frame(image_points, img):\n",
    "    \n",
    "    x0, y0 = image_points[:,0].astype(int)\n",
    "    cv2.circle(img, (x0, y0), 9, (0, 0, 0), -1)\n",
    "\n",
    "    x1, y1 = image_points[:,1].astype(int)\n",
    "    img = cv2.arrowedLine(img, (x0, y0), (x1, y1), (255, 0, 0), 5)  \n",
    "\n",
    "    x2, y2 = image_points[:,2].astype(int)\n",
    "    img = cv2.arrowedLine(img, (x0, y0), (x2, y2), (0, 255, 0), 5)  \n",
    "\n",
    "    x3, y3 = image_points[:,3].astype(int)\n",
    "    img = cv2.arrowedLine(img, (x0, y0), (x3, y3), (0, 0, 255), 5)  \n",
    "\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fd/1_wj4s6n5dz9mph8lxngjxyh0000gn/T/ipykernel_15523/2997839778.py:3: RuntimeWarning: invalid value encountered in cast\n",
      "  x0, y0 = image_points[:,0].astype(int)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'circle'\n> Overload resolution failed:\n>  - Can't parse 'center'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'center'. Sequence item with index 0 has a wrong type\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstone.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdraw_coordinate_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m, in \u001b[0;36mdraw_coordinate_frame\u001b[0;34m(image_points, img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdraw_coordinate_frame\u001b[39m(image_points, img):\n\u001b[1;32m      3\u001b[0m     x0, y0 \u001b[38;5;241m=\u001b[39m image_points[:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcircle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     x1, y1 \u001b[38;5;241m=\u001b[39m image_points[:,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      7\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39marrowedLine(img, (x0, y0), (x1, y1), (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m5\u001b[39m)  \n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'circle'\n> Overload resolution failed:\n>  - Can't parse 'center'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'center'. Sequence item with index 0 has a wrong type\n"
     ]
    }
   ],
   "source": [
    "# Draw the projected points on the image\n",
    "# rgb_image = cv2.cvtColor(frame0, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# Read and display an image (this is just an example image)\n",
    "img = cv2.imread('stone.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "draw_coordinate_frame(image_points, img)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ar_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
